{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "from time import time\n",
    "\n",
    "from numpy import (\n",
    "    dot, float32 as REAL\n",
    ")\n",
    "import numpy as np\n",
    "from gensim import matutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar Modelos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloD2V = Doc2Vec.load(\"./Modelos/modelo2_FINALD2V.model\")\n",
    "modeloW2V = Word2Vec.load(\"./Modelos/modelo10FINAL.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener Vectores e inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUARDAR MODELO SIN INFERENCIA\n",
    "modeloD2V.delete_temporary_training_data(keep_doctags_vectors=False, keep_inference=False)\n",
    "modeloD2V.save('modelofree.model')\n",
    "modeloD2V.trainables.save('neural.mm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferir Vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectores y matriz de inferencia\n",
    "red = modeloD2V.trainables.save('neural.mm')\n",
    "vectorlockf = red.vectors_lockf\n",
    "syn1neg = red.syn1neg\n",
    "del(red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.trainables.vectors_lockf = vectorlockf\n",
    "modelo.trainables.syn1neg = syn1neg\n",
    "del(vectorlockf)\n",
    "del(syn1neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.infer_vector(['hola'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función similiar w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyedvectors = modeloW2V.wv\n",
    "#keyedvectors.save('vectors.kv')\n",
    "del(modeloW2V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### modelo original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['gestor', 'conocimiento']\n",
    "#Modelo W2v\n",
    "similar_words = keyedvectors.most_similar(words, topn=10)\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pesos a las palabras y encontrar la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keyedvectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-fa7338917567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyedvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conocimiento'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeyedvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gestor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#mean = matutils.unitvec(array.mean(axis=0)).astype(REAL)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keyedvectors' is not defined"
     ]
    }
   ],
   "source": [
    "from numpy import (\n",
    "    dot, float32 as REAL\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "from gensim import matutils\n",
    "\n",
    "mean = [keyedvectors.get_vector('conocimiento')*1.0,keyedvectors.get_vector('gestor')*1.0]\n",
    "array = np.array(mean)\n",
    "#mean = matutils.unitvec(array.mean(axis=0)).astype(REAL)\n",
    "array.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectores normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "norms=[]\n",
    "for vector in keyedvectors.vectors:\n",
    "    norms.append(LA.norm(vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Producto punto y normalizar \n",
    "Ordenar de mayor a menor y su cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.dot(keyedvectors.vectors[0:None], mean) / norms[0:None]\n",
    "best = matutils.argsort(dist, topn=10 + 2, reverse=True) \n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encontrar la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyedvectors.index2word[4933]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función Similar W2V old versión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloW2V.wv.init_sims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nariño\n"
     ]
    }
   ],
   "source": [
    "#indice Enumerate\n",
    "#print(modeloW2V.wv.vectors) Vector\n",
    "print(modeloW2V.wv.index2word[1]) # palabra\n",
    "#from numpy import linalg as \n",
    "#LA.norm(vector) Norm Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [modeloW2V.wv.vectors_norm[1]*1.0, modeloW2V.wv.vectors_norm[4]*1.0]\n",
    "array1 = array[0]\n",
    "array_mean=np.array(array).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.004976595592840264, -0.00048409564726171084]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mean = []\n",
    "for vector in array:\n",
    "    final_mean.append(sum(vector.tolist()) / len(vector))\n",
    "final_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(a):\n",
    "    return sum(a) / len(a)\n",
    "\n",
    "mean_list = np.array(list(map(mean, zip(*array)))).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vector.txt', 'w') as f:\n",
    "    for item in mean_list.tolist():\n",
    "        f.write(\"%s,\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "comparison = mean_list == array_mean\n",
    "equal_arrays = comparison.all() \n",
    "  \n",
    "print(equal_arrays) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import (\n",
    "    dot, float32 as REAL\n",
    ")\n",
    "import numpy as np\n",
    "from gensim import matutils\n",
    "\n",
    "mean = matutils.unitvec(np.array(array).mean(axis=0)).astype(REAL)\n",
    "limited = modeloW2V.wv.vectors_norm\n",
    "dist = np.dot(limited, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vector.txt', 'w') as f:\n",
    "    for item in mean.tolist():\n",
    "        f.write(\"%s,\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20,  64,  23, 437, 416, 215, 267,  10, 249, 336])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = matutils.argsort(dist, topn=10, reverse=True)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    4,     1,     5,    12,  7443,  6778, 10108,  6038,  9774,\n",
       "        9615])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean_list\n",
    "best = matutils.argsort(dist, topn=10, reverse=True)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion similar d2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(modeloD2V.docvecs.vectors_docs_norm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(215, 0.6421315670013428),\n",
       " (267, 0.6080042123794556),\n",
       " (10, 0.6039739847183228),\n",
       " (271, 0.6016193628311157),\n",
       " (416, 0.5938380360603333),\n",
       " (437, 0.5845867395401001),\n",
       " (295, 0.5813186168670654),\n",
       " (375, 0.5812559127807617),\n",
       " (39, 0.5790205001831055),\n",
       " (19, 0.5768672823905945)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer = modeloD2V.infer_vector(['conocimiento'])\n",
    "modeloD2V.docvecs.most_similar([infer], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import (\n",
    "    dot, float32 as REAL\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "from gensim import matutils\n",
    "\n",
    "mean = [infer*1.0]\n",
    "array = np.array(mean)\n",
    "mean = matutils.unitvec(array.mean(axis=0)).astype(REAL)\n",
    "#array.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Producto punto y normalizar \n",
    "Ordenar de mayor a menor y su cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20,  64,  23, 437, 416, 215, 267,  10, 249, 336, 309, 444])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = np.dot(modeloD2V.docvecs.vectors_docs_norm[0:None], mean)\n",
    "best = matutils.argsort(dist, topn=10 + 2, reverse=True) \n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encontrar la palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyedvectors.index2word[4933]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectores a ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch()\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creación de indices Palabras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'palabras'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_palabras=\"\"\"\n",
    "{\n",
    "    \"mappings\":{\n",
    "        \"properties\":{\n",
    "            \"index\":{\"type\": \"integer\"},\n",
    "            \"palabra\":{\"type\": \"keyword\"},\n",
    "            \"vector\":{\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 300\n",
    "            },\n",
    "            \"norm_vec\":{\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 300\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "# es.indices.delete(index='palabras')\n",
    "es.indices.create(body=mapping_palabras, index='palabras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creación de indices Documentos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'documentos'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_docs=\"\"\"\n",
    "{\n",
    "    \"mappings\":{\n",
    "        \"properties\":{\n",
    "            \"tag\":{\"type\": \"integer\"},\n",
    "            \"vector\":{\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 300\n",
    "            },\n",
    "            \"norm_vec\":{\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 300\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "# es.indices.delete(index='documentos')\n",
    "es.indices.create(body=mapping_docs, index='documentos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'palabras': {'aliases': {}, 'mappings': {'properties': {'index': {'type': 'integer'}, 'norm_vec': {'type': 'dense_vector', 'dims': 300}, 'palabra': {'type': 'keyword'}, 'vector': {'type': 'dense_vector', 'dims': 300}}}, 'settings': {'index': {'creation_date': '1608162403100', 'number_of_shards': '1', 'number_of_replicas': '1', 'uuid': 'v2mqowdGSuGXzRYCOihh3A', 'version': {'created': '7060099'}, 'provided_name': 'palabras'}}}}\n",
      "\n",
      "{'documentos': {'aliases': {}, 'mappings': {'properties': {'norm_vec': {'type': 'dense_vector', 'dims': 300}, 'tag': {'type': 'integer'}, 'vector': {'type': 'dense_vector', 'dims': 300}}}, 'settings': {'index': {'creation_date': '1607123586198', 'number_of_shards': '1', 'number_of_replicas': '1', 'uuid': 'hFkHM_O3TWmms3zkhR36BQ', 'version': {'created': '7060099'}, 'provided_name': 'documentos'}}}}\n"
     ]
    }
   ],
   "source": [
    "print(es.indices.get('palabras'), end='\\n\\n')\n",
    "print(es.indices.get('documentos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datos para Palabras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(modeloW2V.wv.vocab['diagnostico'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 11445, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "# for i, (vector, vector_norm, palabra) in enumerate(zip(modeloW2V.wv.vectors, modeloW2V.wv.vectors_norm, modeloW2V.wv.vocab.keys())):\n",
    "\n",
    "#     data = {\n",
    "#         \"index\":i,\n",
    "#         \"palabra\":palabra,\n",
    "#         \"vector\":vector,\n",
    "#         \"norm_vec\":vector_norm\n",
    "#     }\n",
    "\n",
    "#     es.index(index=\"palabras\", body=data, id=i)\n",
    "\n",
    "# print(es.count(index='palabras'))\n",
    "\n",
    "for key, value in modeloW2V.wv.vocab.items():\n",
    "    \n",
    "    index = value.index\n",
    "    vector = modeloW2V.wv.vectors[index]\n",
    "    vector_norm = modeloW2V.wv.vectors_norm[index]\n",
    "    data = {\n",
    "        \"doc\":{\n",
    "            \"index\":index,\n",
    "            \"palabra\":key,\n",
    "            \"vector\":vector,\n",
    "            \"norm_vec\":vector_norm\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    es.index(index=\"palabras\", body=data, id=index)\n",
    "    es.update(index=\"palabras\", body=data, id=index)\n",
    "    \n",
    "    \n",
    "print(es.count(index='palabras'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datos Documentos D2V**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 451, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "for i, (vector, vector_norm) in enumerate(zip(modeloD2V.docvecs.vectors_docs, modeloD2V.docvecs.vectors_docs_norm)):\n",
    "\n",
    "    data = {\n",
    "        \"tag\":i+1,\n",
    "        \"vector\":vector,\n",
    "        \"norm_vec\":vector_norm\n",
    "    }\n",
    "\n",
    "    es.index(index=\"documentos\", body=data, id=i+1)\n",
    "\n",
    "print(es.count(index='documentos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando algoritmos desde Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabra = es.get(index='palabras', id=1)['_source']\n",
    "type(palabra['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W2V Most Similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consultamos los vectores correspondientes a las palabras a buscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vecs = {\n",
    "    \"query\":{\n",
    "        \"bool\":{\n",
    "            \"should\":[\n",
    "                {\"term\": { \"palabra\": \"ontologias\" }}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"_source\": [\"palabra\", \"norm_vec\"]\n",
    "}\n",
    "vectores = es.search(index='palabras', body=query_vecs)['hits']['hits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la Media de los vectores y transformamos a vector unitario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vecs = [vector['_source']['norm_vec'] for vector in vectores]\n",
    "vector_mean = np.array(norm_vecs).mean(axis=0)\n",
    "unit_vec = vector_mean / np.linalg.norm(vector_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos producto Punto en ElasticSearch y miramos el puntaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2202, 'ontologias', 1.0),\n",
       " (4918, 'gestor', 0.85891134),\n",
       " (6645, 'sparql', 0.8413498),\n",
       " (6680, 'umayux', 0.8379714),\n",
       " (11329, 'buscador', 0.8294513),\n",
       " (4933, 'debilmente', 0.82685596),\n",
       " (11195, 'solicitada', 0.82475597),\n",
       " (6646, 'rdf', 0.8210847),\n",
       " (11316, 'evacuacion', 0.81534725),\n",
       " (11379, 'maskana', 0.8088352),\n",
       " (6643, 'motor', 0.80510694)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_sims = {\n",
    "  \"query\": {\n",
    "    \"script_score\": {\n",
    "      \"query\": {\n",
    "        \"match_all\": {}\n",
    "       },\n",
    "      \"script\": {\n",
    "        \"id\": \"dot_product\",\n",
    "        \"params\": {\n",
    "          \"query_vector\": unit_vec\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"size\": 11,\n",
    "  \"_source\": [\"palabra\", \"index\"]\n",
    "}\n",
    "most_similar = es.search(index='palabras', body=query_sims)['hits']['hits']\n",
    "most_similar = [(palabra['_source']['index'],palabra['_source']['palabra'], palabra['_score']) for palabra in most_similar]\n",
    "most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gestor', 0.8589113354682922),\n",
       " ('sparql', 0.8413498997688293),\n",
       " ('umayux', 0.8379713296890259),\n",
       " ('buscador', 0.829451322555542),\n",
       " ('debilmente', 0.8268558979034424),\n",
       " ('solicitada', 0.8247559666633606),\n",
       " ('rdf', 0.82108473777771),\n",
       " ('evacuacion', 0.8153471946716309),\n",
       " ('maskana', 0.8088351488113403),\n",
       " ('motor', 0.8051068782806396)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['ontologias']\n",
    "similar_words = modeloW2V.wv.most_similar(words, topn=10)\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2V Most Similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferimos el Vector y calculamos la Media, luego se transforma  vector unitario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_vec = [modeloD2V.infer_vector(['medicina'])]\n",
    "vec_mean_doc = np.array(infer_vec).mean(axis=0)\n",
    "unit_vec_doc = vec_mean_doc / np.linalg.norm(vec_mean_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la consulta a Elastic con producto Punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(371, 0.60009134),\n",
       " (93, 0.5903249),\n",
       " (5, 0.58496916),\n",
       " (56, 0.57999855),\n",
       " (244, 0.57189333),\n",
       " (96, 0.56820834),\n",
       " (405, 0.56594735),\n",
       " (440, 0.56486785),\n",
       " (315, 0.56443554),\n",
       " (60, 0.5625713)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_sims_docs = {\n",
    "  \"query\": {\n",
    "    \"script_score\": {\n",
    "      \"query\": {\n",
    "        \"match_all\": {}\n",
    "       },\n",
    "      \"script\": {\n",
    "        \"id\": \"dot_product\",\n",
    "        \"params\": {\n",
    "          \"query_vector\": unit_vec_doc\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"size\": 10,\n",
    "  \"_source\": [\"tag\"]\n",
    "}\n",
    "\n",
    "most_similar_docs = es.search(index='documentos', body=query_sims_docs)['hits']['hits']\n",
    "most_similar_docs = [(doc['_source']['tag'], doc['_score']) for doc in most_similar_docs]\n",
    "# most_similar_docs = [doc['_source']['tag'] for doc in most_similar]\n",
    "most_similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(371, 0.6050417423248291)\n",
      "(93, 0.5903229713439941)\n",
      "(56, 0.5860195159912109)\n",
      "(139, 0.5759848356246948)\n",
      "(440, 0.5720837116241455)\n",
      "(5, 0.5701383352279663)\n",
      "(405, 0.5683046579360962)\n",
      "(381, 0.565326988697052)\n",
      "(60, 0.5643856525421143)\n",
      "(244, 0.5641034841537476)\n"
     ]
    }
   ],
   "source": [
    "infer = modeloD2V.infer_vector(['medicina'])\n",
    "sims_docs = modeloD2V.docvecs.most_similar([infer], topn=10)\n",
    "for doc in sims_docs:\n",
    "    print(f'({doc[0]+1}, {doc[1]})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tesis)",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
