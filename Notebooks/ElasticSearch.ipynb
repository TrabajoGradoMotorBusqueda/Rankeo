{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "from time import time\n",
    "\n",
    "from numpy import (\n",
    "    dot, float32 as REAL\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar Modelos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloD2V = Doc2Vec.load(\"./Modelos/modelo2_FINALD2V.model\")\n",
    "modeloW2V = Word2Vec.load(\"./Modelos/modelo10FINAL.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectores a ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch()\n",
    "es.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creación de indices Palabras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'palabras'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_palabras=\"\"\"\n",
    "{\n",
    "    \"mappings\":{\n",
    "        \"properties\":{\n",
    "            \"index\":{\"type\": \"integer\"},\n",
    "            \"palabra\":{\"type\": \"keyword\"},\n",
    "            \"vector\":{\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 300\n",
    "            },\n",
    "            \"norm_vec\":{\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 300\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "# es.indices.delete(index='palabras')\n",
    "es.indices.create(body=mapping_palabras, index='palabras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**creación de indices Documentos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'documentos'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_docs=\"\"\"\n",
    "{\n",
    "    \"mappings\":{\n",
    "        \"properties\":{\n",
    "            \"tag\":{\"type\": \"integer\"},\n",
    "            \"vector\":{\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 300\n",
    "            },\n",
    "            \"norm_vec\":{\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 300\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "# es.indices.delete(index='documentos')\n",
    "es.indices.create(body=mapping_docs, index='documentos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'palabras': {'aliases': {}, 'mappings': {'properties': {'index': {'type': 'integer'}, 'norm_vec': {'type': 'dense_vector', 'dims': 300}, 'palabra': {'type': 'keyword'}, 'vector': {'type': 'dense_vector', 'dims': 300}}}, 'settings': {'index': {'creation_date': '1608162403100', 'number_of_shards': '1', 'number_of_replicas': '1', 'uuid': 'v2mqowdGSuGXzRYCOihh3A', 'version': {'created': '7060099'}, 'provided_name': 'palabras'}}}}\n",
      "\n",
      "{'documentos': {'aliases': {}, 'mappings': {'properties': {'norm_vec': {'type': 'dense_vector', 'dims': 300}, 'tag': {'type': 'integer'}, 'vector': {'type': 'dense_vector', 'dims': 300}}}, 'settings': {'index': {'creation_date': '1607123586198', 'number_of_shards': '1', 'number_of_replicas': '1', 'uuid': 'hFkHM_O3TWmms3zkhR36BQ', 'version': {'created': '7060099'}, 'provided_name': 'documentos'}}}}\n"
     ]
    }
   ],
   "source": [
    "print(es.indices.get('palabras'), end='\\n\\n')\n",
    "print(es.indices.get('documentos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datos para Palabras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(modeloW2V.wv.vocab['diagnostico'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 11445, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "# for i, (vector, vector_norm, palabra) in enumerate(zip(modeloW2V.wv.vectors, modeloW2V.wv.vectors_norm, modeloW2V.wv.vocab.keys())):\n",
    "\n",
    "#     data = {\n",
    "#         \"index\":i,\n",
    "#         \"palabra\":palabra,\n",
    "#         \"vector\":vector,\n",
    "#         \"norm_vec\":vector_norm\n",
    "#     }\n",
    "\n",
    "#     es.index(index=\"palabras\", body=data, id=i)\n",
    "\n",
    "# print(es.count(index='palabras'))\n",
    "\n",
    "for key, value in modeloW2V.wv.vocab.items():\n",
    "    \n",
    "    index = value.index\n",
    "    vector = modeloW2V.wv.vectors[index]\n",
    "    vector_norm = modeloW2V.wv.vectors_norm[index]\n",
    "    data = {\n",
    "        \"doc\":{\n",
    "            \"index\":index,\n",
    "            \"palabra\":key,\n",
    "            \"vector\":vector,\n",
    "            \"norm_vec\":vector_norm\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    es.index(index=\"palabras\", body=data, id=index)\n",
    "    es.update(index=\"palabras\", body=data, id=index)\n",
    "    \n",
    "    \n",
    "print(es.count(index='palabras'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datos Documentos D2V**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 451, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "for i, (vector, vector_norm) in enumerate(zip(modeloD2V.docvecs.vectors_docs, modeloD2V.docvecs.vectors_docs_norm)):\n",
    "\n",
    "    data = {\n",
    "        \"tag\":i+1,\n",
    "        \"vector\":vector,\n",
    "        \"norm_vec\":vector_norm\n",
    "    }\n",
    "\n",
    "    es.index(index=\"documentos\", body=data, id=i+1)\n",
    "\n",
    "print(es.count(index='documentos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando algoritmos desde Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabra = es.get(index='palabras', id=1)['_source']\n",
    "type(palabra['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W2V Most Similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consultamos los vectores correspondientes a las palabras a buscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vecs = {\n",
    "    \"query\":{\n",
    "        \"bool\":{\n",
    "            \"should\":[\n",
    "                {\"term\": { \"palabra\": \"ontologias\" }},\n",
    "                {\"term\": { \"palabra\": \"randompalabra\" }}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"_source\": [\"palabra\", \"norm_vec\"]\n",
    "}\n",
    "vectores = es.search(index='palabras', body=query_vecs)['hits']['hits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la Media de los vectores y transformamos a vector unitario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vecs = [vector['_source']['norm_vec'] for vector in vectores]\n",
    "vector_mean = np.array(norm_vecs).mean(axis=0)\n",
    "unit_vec = vector_mean / np.linalg.norm(vector_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos producto Punto en ElasticSearch y miramos el puntaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2202, 'ontologias', 1.0),\n",
       " (4918, 'gestor', 0.85891134),\n",
       " (6645, 'sparql', 0.8413498),\n",
       " (6680, 'umayux', 0.8379714),\n",
       " (11329, 'buscador', 0.8294513),\n",
       " (4933, 'debilmente', 0.82685596),\n",
       " (11195, 'solicitada', 0.82475597),\n",
       " (6646, 'rdf', 0.8210847),\n",
       " (11316, 'evacuacion', 0.81534725),\n",
       " (11379, 'maskana', 0.8088352),\n",
       " (6643, 'motor', 0.80510694)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_sims = {\n",
    "  \"query\": {\n",
    "    \"script_score\": {\n",
    "      \"query\": {\n",
    "        \"match_all\": {}\n",
    "       },\n",
    "      \"script\": {\n",
    "        \"id\": \"dot_product\",\n",
    "        \"params\": {\n",
    "          \"query_vector\": unit_vec\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"size\": 11,\n",
    "  \"_source\": [\"palabra\", \"index\"]\n",
    "}\n",
    "most_similar = es.search(index='palabras', body=query_sims)['hits']['hits']\n",
    "most_similar = [(palabra['_source']['index'],palabra['_source']['palabra'], palabra['_score']) for palabra in most_similar]\n",
    "most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('debilmente', 0.77090984582901),\n",
       " ('umayux', 0.7446715831756592),\n",
       " ('sgbd', 0.7438246011734009),\n",
       " ('sparql', 0.7421228885650635),\n",
       " ('rdf', 0.7153308391571045),\n",
       " ('postgresql', 0.7092360854148865),\n",
       " ('ontologias', 0.7078660726547241),\n",
       " ('fundamentandose', 0.699651837348938),\n",
       " ('solicitada', 0.6902329921722412),\n",
       " ('maskana', 0.6835665702819824)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['gestor', 'conocimiento']\n",
    "similar_words = modeloW2V.wv.most_similar(words, topn=10)\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2V Most Similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferimos el Vector y calculamos la Media, luego se transforma  vector unitario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_vec = [modeloD2V.infer_vector(['gestor','conocimiento'])]\n",
    "vec_mean_doc = np.array(infer_vec).mean(axis=0)\n",
    "unit_vec_doc = vec_mean_doc / np.linalg.norm(vec_mean_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la consulta a Elastic con producto Punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(443, 0.6676931),\n",
       " (422, 0.62167925),\n",
       " (438, 0.6189302),\n",
       " (417, 0.6073199),\n",
       " (435, 0.6052244),\n",
       " (139, 0.55522835),\n",
       " (337, 0.55080765),\n",
       " (65, 0.5423171),\n",
       " (445, 0.5416863),\n",
       " (21, 0.54074764)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_sims_docs = {\n",
    "  \"query\": {\n",
    "    \"script_score\": {\n",
    "      \"query\": {\n",
    "        \"match_all\": {}\n",
    "       },\n",
    "      \"script\": {\n",
    "        \"id\": \"dot_product\",\n",
    "        \"params\": {\n",
    "          \"query_vector\": unit_vec_doc\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"size\": 10,\n",
    "  \"_source\": [\"tag\"]\n",
    "}\n",
    "\n",
    "most_similar_docs = es.search(index='documentos', body=query_sims_docs)['hits']['hits']\n",
    "most_similar_docs = [(doc['_source']['tag'], doc['_score']) for doc in most_similar_docs]\n",
    "# most_similar_docs = [doc['_source']['tag'] for doc in most_similar]\n",
    "most_similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 0.6732131242752075)\n",
      "(438, 0.6272218227386475)\n",
      "(417, 0.6206049919128418)\n",
      "(422, 0.6184952855110168)\n",
      "(435, 0.6097984910011292)\n",
      "(139, 0.5551089644432068)\n",
      "(337, 0.5512728691101074)\n",
      "(425, 0.5449885129928589)\n",
      "(445, 0.5434989929199219)\n",
      "(444, 0.5386724472045898)\n"
     ]
    }
   ],
   "source": [
    "infer = modeloD2V.infer_vector(['gestor','conocimiento'])\n",
    "sims_docs = modeloD2V.docvecs.most_similar([infer], topn=10)\n",
    "for doc in sims_docs:\n",
    "    print(f'({doc[0]+1}, {doc[1]})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tesis)",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
