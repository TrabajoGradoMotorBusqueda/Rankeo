{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos Ontologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../Scripts')\n",
    "import pandas as pd \n",
    "from ontologia import *\n",
    "import ast\n",
    "import difflib\n",
    "\n",
    "#Lectura de lemas \n",
    "import json\n",
    "with open('./Vocabulario/diccionario-lemas.json', 'r') as f:\n",
    "    diccionario_lemas = json.loads(f.read())\n",
    "\n",
    "lemas = list(diccionario_lemas.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos Modelo W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from time import time\n",
    "\n",
    "modelo = Word2Vec.load(\"./Modelos/modelo10FINAL.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words=['gestor',\n",
    "# 'conocimiento',\n",
    "# 'sgbd',\n",
    "# 'debilmente',\n",
    "# 'postgresql',\n",
    "# 'sparql',\n",
    "# 'umayux',\n",
    "# 'tacito',\n",
    "# 'semantica',\n",
    "# 'motor',\n",
    "# 'rdf',\n",
    "# 'explicito']\n",
    "\n",
    "# words=['optica', 'progresista', 'ancladas', 'civilizacion',\n",
    "# 'provinciales',\n",
    "# 'opticos',\n",
    "# 'promueven',\n",
    "# 'retro',\n",
    "# 'irradiadas',\n",
    "# 'fenomenologia',\n",
    "# 'representantes',\n",
    "# 'guerreras',\n",
    "# 'moderna',\n",
    "# 'transparencia',\n",
    "# 'sustituido','amino',\n",
    "# 'rebeldias',\n",
    "# 'historiografia',\n",
    "# 'propicio','deconstruccion',\n",
    "# 'lineal'\n",
    "#       ]\n",
    "\n",
    "# words=['medicina', 'natural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inteligencia',\n",
       " 'artificial',\n",
       " 'potentes',\n",
       " 'fundamentandose',\n",
       " 'pentaho',\n",
       " 'pyme',\n",
       " 'idoneo',\n",
       " 'rdf',\n",
       " 'kimball',\n",
       " 'computacion',\n",
       " 'makipuray',\n",
       " 'spago',\n",
       " 'sescca',\n",
       " 'predictiva',\n",
       " 'imaraña',\n",
       " 'source',\n",
       " 'open',\n",
       " 'potencien',\n",
       " 'sparql',\n",
       " 'constituya',\n",
       " 'negocios',\n",
       " 'helicoidal',\n",
       " 'artificiales',\n",
       " 'potente',\n",
       " 'computacional',\n",
       " 'predictivo',\n",
       " 'negocio']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['inteligencia', 'artificial']\n",
    "#Modelo W2v\n",
    "similar_words = modelo.wv.most_similar(words, topn=20)\n",
    "\n",
    "words.extend([word[0] for word in similar_words])\n",
    "\n",
    "#Palabras en plural o muy similares\n",
    "more_words=[]\n",
    "for word in words:\n",
    "    additional = difflib.get_close_matches(word, diccionario_lemas.keys(), n=5, cutoff=0.90)\n",
    "    more_words.extend(additional[1:])\n",
    "    \n",
    "#Añadir palabras finales\n",
    "words.extend(more_words)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperacion con OR2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_instances=[]\n",
    "\n",
    "for word in words:\n",
    "    instance = ontologia.search(descripcion_palabra=word)\n",
    "    words_instances.extend(instance)\n",
    "\n",
    "#print(words_instances)\n",
    "docs = []\n",
    "id_docs = []\n",
    "for word in words_instances:\n",
    "    for doc in word.palabra_describe_pi:\n",
    "        id_doc = doc.get_id_proyecto_investigacion()[0]\n",
    "        id_docs.append(id_doc)\n",
    "        docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking by Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(422, 7),\n",
       " (94, 5),\n",
       " (311, 5),\n",
       " (417, 5),\n",
       " (63, 4),\n",
       " (445, 4),\n",
       " (22, 3),\n",
       " (223, 2),\n",
       " (435, 2),\n",
       " (438, 2),\n",
       " (389, 2),\n",
       " (303, 2),\n",
       " (404, 2),\n",
       " (24, 2),\n",
       " (407, 2),\n",
       " (54, 2),\n",
       " (189, 2),\n",
       " (340, 2),\n",
       " (287, 2),\n",
       " (120, 1),\n",
       " (419, 1),\n",
       " (442, 1),\n",
       " (361, 1),\n",
       " (363, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (28, 1),\n",
       " (34, 1),\n",
       " (38, 1),\n",
       " (51, 1),\n",
       " (72, 1),\n",
       " (76, 1),\n",
       " (85, 1),\n",
       " (129, 1),\n",
       " (134, 1),\n",
       " (141, 1),\n",
       " (160, 1),\n",
       " (171, 1),\n",
       " (177, 1),\n",
       " (196, 1),\n",
       " (200, 1),\n",
       " (249, 1),\n",
       " (253, 1),\n",
       " (278, 1),\n",
       " (279, 1),\n",
       " (308, 1),\n",
       " (338, 1),\n",
       " (350, 1),\n",
       " (384, 1),\n",
       " (385, 1),\n",
       " (397, 1),\n",
       " (431, 1),\n",
       " (33, 1),\n",
       " (154, 1),\n",
       " (247, 1),\n",
       " (248, 1),\n",
       " (250, 1),\n",
       " (293, 1),\n",
       " (138, 1),\n",
       " (258, 1),\n",
       " (309, 1),\n",
       " (405, 1),\n",
       " (17, 1),\n",
       " (19, 1),\n",
       " (77, 1),\n",
       " (111, 1),\n",
       " (291, 1),\n",
       " (369, 1),\n",
       " (370, 1),\n",
       " (371, 1),\n",
       " (381, 1),\n",
       " (440, 1),\n",
       " (2, 1),\n",
       " (64, 1),\n",
       " (261, 1),\n",
       " (21, 1),\n",
       " (65, 1),\n",
       " (105, 1),\n",
       " (310, 1)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(id_docs).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial list [14, 15, 21, 24, 35, 47, 65, 66, 67, 113, 120, 124, 133, 161, 172, 180, 200, 204, 251, 257, 270, 272, 284, 294, 301, 311, 319, 364, 384, 406, 407, 408, 417, 418, 419, 445, 13, 14, 15, 19, 21, 24, 65, 106, 110, 123, 134, 159, 163, 180, 192, 223, 224, 232, 234, 237, 247, 248, 251, 279, 282, 284, 311, 318, 319, 320, 348, 405, 407, 445, 449, 14, 15, 21, 106, 149, 163, 206, 220, 251, 311, 15, 251, 65, 417, 180, 15, 23, 14, 15, 21, 407, 417, 15, 27, 14, 15, 21, 24, 65, 180, 407, 419, 180, 15, 196, 283, 284, 15, 237, 106, 21, 24, 65, 204, 449, 163, 406, 180, 21, 24, 39, 66, 88, 95, 169, 170, 251, 283, 284, 297, 347, 375, 394, 396, 418, 448, 63, 66, 110, 134, 153, 272, 297, 354, 355, 356, 360, 386, 54, 340, 7, 8, 212, 115, 233, 308, 4, 10, 12, 13, 17, 19, 26, 32, 34, 38, 51, 55, 59, 60, 61, 62, 64, 66, 70, 72, 76, 79, 81, 85, 109, 111, 114, 119, 120, 126, 127, 136, 137, 138, 143, 146, 147, 148, 149, 162, 167, 171, 191, 192, 204, 205, 208, 211, 215, 217, 223, 227, 231, 241, 242, 246, 247, 248, 258, 262, 265, 269, 270, 280, 284, 287, 292, 293, 296, 297, 299, 302, 316, 320, 321, 326, 327, 330, 331, 334, 336, 338, 341, 342, 346, 348, 363, 374, 377, 378, 382, 385, 388, 392, 402, 404, 408, 409, 412, 416, 418, 419, 423, 427, 437, 442, 76, 105, 287, 439, 451, 27, 13, 14, 23, 26, 34, 38, 58, 69, 73, 76, 90, 92, 105, 131, 133, 153, 167, 175, 180, 181, 194, 209, 210, 223, 237, 242, 245, 247, 248, 253, 259, 264, 269, 281, 293, 299, 312, 320, 345, 350, 352, 364, 411, 419, 424, 428, 173, 399, 42, 133] Cantidad: 319\n",
      "final list [15, 21, 180, 14, 24, 65, 251, 284, 66, 407, 419, 133, 204, 311, 417, 418, 13, 106, 163, 223, 237, 247, 248, 320, 297, 76, 120, 270, 272, 319, 364, 406, 408, 445, 19, 110, 134, 192, 348, 449, 149, 23, 27, 283, 153, 26, 34, 38, 167, 242, 269, 287, 293, 299, 105, 35, 47, 67, 113, 124, 161, 172, 200, 257, 294, 301, 384, 123, 159, 224, 232, 234, 279, 282, 318, 405, 206, 220, 196, 39, 88, 95, 169, 170, 347, 375, 394, 396, 448, 63, 354, 355, 356, 360, 386, 54, 340, 7, 8, 212, 115, 233, 308, 4, 10, 12, 17, 32, 51, 55, 59, 60, 61, 62, 64, 70, 72, 79, 81, 85, 109, 111, 114, 119, 126, 127, 136, 137, 138, 143, 146, 147, 148, 162, 171, 191, 205, 208, 211, 215, 217, 227, 231, 241, 246, 258, 262, 265, 280, 292, 296, 302, 316, 321, 326, 327, 330, 331, 334, 336, 338, 341, 342, 346, 363, 374, 377, 378, 382, 385, 388, 392, 402, 404, 409, 412, 416, 423, 427, 437, 442, 439, 451, 58, 69, 73, 90, 92, 131, 175, 181, 194, 209, 210, 245, 253, 259, 264, 281, 312, 345, 350, 352, 411, 424, 428, 173, 399, 42] Cantidad: 209\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "from itertools import repeat, chain \n",
    "    \n",
    "# printing initial ini_list \n",
    "print (\"initial list\", str(id_docs), \"Cantidad:\" ,len(id_docs)) \n",
    "  \n",
    "# sorting on bais of frequency of elements \n",
    "result = list(chain(i for i, c in Counter(id_docs).most_common())) \n",
    "  \n",
    "# printing final result \n",
    "print(\"final list\", str(result), \"Cantidad:\",len(result)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking con Instancias de Documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial list Cantidad: 117\n",
      "final list Cantidad: 79\n"
     ]
    }
   ],
   "source": [
    "# printing initial ini_list \n",
    "print (\"initial list\", \"Cantidad:\" ,len(docs)) \n",
    "  \n",
    "# sorting on bais of frequency of elements \n",
    "result = list(chain(i for i, c in Counter(docs).most_common())) \n",
    "  \n",
    "# printing final result \n",
    "print(\"final list\", \"Cantidad:\" ,len(result)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) ['MOTOR DE BÚSQUEDA INTELIGENTE DE INFORMES DE INVESTIGACIÓN BASADO EN RECURSOS SEMÁNTICOS PARA EL SISTEMA DE INVESTIGACIONES DE LA UNIVERSIDAD DE NARIÑO']\n",
      "(2) ['Efecto del Sistema Electrónico para el Suministro de Contingencias en el Comportamiento en el Aula de Clases (SESCCA)']\n",
      "(3) ['ANÁLISIS DE FUNCIONALIDAD DE LA HERRAMIENTA DE INTELIGENCIA DE NEGOCIOS DE SOFTWARE LIBRE SPAGO BI ORIENTADA AL USO EN LAS PYMES DE LA REGIÓN']\n",
      "(4) ['MAKIPURAY: UNA HERRAMIENTA WEB DE INTELIGENCIA DE NEGOCIOS PARA EL DESCUBRIMIENTO DE CONOCIMIENTO ORIENTADA A LAS PYME DEL DEPARTAMENTO DE NARIÑO']\n",
      "(5) ['Desarrollo de una metodología de visualización interactiva y eficaz de información en Big Data.']\n",
      "(6) ['UN MERCADO DE DATOS PARA EL ANÁLISIS MULTIDIMENSIONAL DE LAS PRUEBAS SABER 5 DE LAS INSTITUCIONES EDUCATIVAS DE LOS MUNICIPIOS DE LA SUBREGIÓN DE OBANDO DEL DEPARTAMENTO DE NARIÑO']\n",
      "(7) ['APLICACIÓN DE LA TÉCNICA \"DEEP LEARNING\" EN LA CLASIFICACIÓN DE SISMOS DE LOS TIPOS LP Y VT DEL VOLCÁN GALERAS']\n",
      "(8) ['La Acción Comunicativa de los Maestros del Nivel de Educación Básica Primaria: Un referente para la Formación Inicial de los maestros']\n",
      "(9) ['Rikhuna: Visor cartográfico inteligente de direcciones urbanas y sitios de interés del municipio de Pasto basado en PostGIS.']\n",
      "(10) ['SITAPP: UNA APLICACIÓN INTELIGENTE PARA DISPOSITIVOS MÓVILES DEL SISTEMA DE RUTAS DE TRANSPORTE URBANO DEL MUNICIPIO DE PASTO']\n",
      "(11) ['Evaluación de la producción de oxígeno de las microalgas Spirulina sp y Chlorella sp en un fotobiorreactor tubular helicoidal.']\n",
      "(12) ['Una mirada computacional a la Teoría Algebraica de Códigos']\n",
      "(13) ['Fractales, matemáticas y algoritmos']\n",
      "(14) ['APLICACIÓN DE TÉCNICAS DE MINERÍA DE DATOS PARA EL DESCUBRIMIENTO DE FACTORES ASOCIADOS AL DESEMPEÑO ACADÉMICO EN LAS PRUEBAS SABER 5° DE LOS ESTUDIANTES DE LAS INSTITUCIONES EDUCATIVAS DEL DEPARTAMENTO DE NARIÑO.']\n",
      "(15) ['IMARAÑA: UNA HERRAMIENTA WEB DE ANALÍTICA DE DATOS BASADA EN EL LENGUAJE R PARA SOPORTAR LA TOMA DE DECISIONES EN LAS PYMES DEL DEPARTAMENTO DE NARIÑO']\n",
      "(16) ['COYUNTURA ECONOMICA Y SOCIAL DE LOS HOGARES URBANOS DEL MUNICIPIO DE PASTO, 2014']\n",
      "(17) ['Formas de habitar el espacio universitario: laboratorio nómada de experiencias estéticas de la facultad de artes']\n",
      "(18) ['COYUNTURA SOCIAL DE LOS HOGARES URBANOS DEL MUNICIPIO DE TUQUERRES 2018']\n",
      "(19) ['Seguimiento a los graduados del programa de Contaduría Pública de la Universidad de Nariño y su impacto en el medio laboral durante los años 2016-2018']\n",
      "(20) ['Estudio de la diversidad de los indicadores de contaminación fecal Escherichia coli y colifagos somáticos en el Lago Guamuéz, ecosistema estratégico productivo de Nariño.']\n"
     ]
    }
   ],
   "source": [
    "for index, doc in enumerate(result[:20]):\n",
    "    title = doc.get_titulo_proyecto_investigacion()\n",
    "    print(f'({index+1}) {title}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tesis)",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
